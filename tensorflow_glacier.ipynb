{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>271f93f4</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              band_1  \\\n",
       "0  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                              band_2        id inc_angle  \\\n",
       "0  [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
       "1  [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
       "2  [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
       "3  [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
       "4  [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
       "\n",
       "   is_iceberg  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json('./data/train.json')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1604, 5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5625"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[\"band_2\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The training dataset consists of 1604 rows. Each row has data about two photos (band_1, band_2) represented by a 75x75 array \n",
    "of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1604"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"images\"] = [ np.vstack((train[\"band_1\"][t], train[\"band_2\"][t])).T  for t in range(0, train.shape[0]) ]\n",
    "## train[\"images\"] = [ [ train[\"band_1\"][t], train[\"band_2\"][t] ] for t in range(0, len(train)) ]\n",
    "train[\"images\"].ndim\n",
    "\n",
    "train[\"input\"] = [ np.array(train.band_1[t], dtype=np.float32) for t in range(0, len(train))  ]\n",
    "train.input[0]\n",
    "\n",
    "\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "5       1\n",
       "6       1\n",
       "7       0\n",
       "8       0\n",
       "9       0\n",
       "10      1\n",
       "11      0\n",
       "12      1\n",
       "13      1\n",
       "14      0\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      1\n",
       "20      0\n",
       "21      1\n",
       "22      0\n",
       "23      1\n",
       "24      0\n",
       "25      1\n",
       "26      1\n",
       "27      0\n",
       "28      1\n",
       "29      0\n",
       "       ..\n",
       "1574    0\n",
       "1575    0\n",
       "1576    0\n",
       "1577    0\n",
       "1578    0\n",
       "1579    0\n",
       "1580    0\n",
       "1581    0\n",
       "1582    0\n",
       "1583    0\n",
       "1584    0\n",
       "1585    0\n",
       "1586    0\n",
       "1587    0\n",
       "1588    0\n",
       "1589    0\n",
       "1590    0\n",
       "1591    0\n",
       "1592    0\n",
       "1593    0\n",
       "1594    0\n",
       "1595    0\n",
       "1596    0\n",
       "1597    0\n",
       "1598    0\n",
       "1599    0\n",
       "1600    0\n",
       "1601    0\n",
       "1602    0\n",
       "1603    0\n",
       "Name: is_iceberg, Length: 1604, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 5625 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 2 # MNIST total classes (0-9 digits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Define the input function for training\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "y_train = to_categorical(np.array(train[\"is_iceberg\"]))\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': x_band1 }, y=y_train,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def neural_net(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['images']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Akshata\\AppData\\Local\\Temp\\tmpfk9fn78v\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Akshata\\\\AppData\\\\Local\\\\Temp\\\\tmpfk9fn78v', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-1b71576b09d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Akshata\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[0;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Akshata\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m       estimator_spec = self._call_model_fn(features, labels,\n\u001b[1;32m--> 560\u001b[1;33m                                            model_fn_lib.ModeKeys.TRAIN)\n\u001b[0m\u001b[0;32m    561\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m       all_hooks.extend([\n",
      "\u001b[1;32mC:\\Users\\Akshata\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     model_fn_results = self._model_fn(\n\u001b[1;32m--> 545\u001b[1;33m         features=features, labels=labels, **kwargs)\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-190-97f2872c1740>\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Define loss and optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m---> 17\u001b[1;33m         logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Akshata\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   1684\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[0;32m   1685\u001b[0m                        \u001b[1;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1686\u001b[1;33m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[0;32m   1687\u001b[0m     \u001b[1;31m# Check if no reshapes are required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 3)."
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find trained model in model_dir: C:\\Users\\Akshata\\AppData\\Local\\Temp\\tmpmi0zowum.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-c43b8e9ba107>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     batch_size=batch_size, shuffle=False)\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Use the Estimator 'evaluate' method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Akshata\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m   def predict(self,\n",
      "\u001b[1;32mC:\\Users\\Akshata\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[1;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    624\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlatest_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         raise ValueError('Could not find trained model in model_dir: {}.'.\n\u001b[1;32m--> 626\u001b[1;33m                          format(self._model_dir))\n\u001b[0m\u001b[0;32m    627\u001b[0m       \u001b[0mcheckpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlatest_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not find trained model in model_dir: C:\\Users\\Akshata\\AppData\\Local\\Temp\\tmpmi0zowum."
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Akshata\\AppData\\Local\\Temp\\tmpjx09dhge\\model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD3CAYAAAA0cknjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngEGXMvB/lp56Iefqd/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7894b1400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD3CAYAAAA0cknjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7890f8da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD3CAYAAAA0cknjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niy4lYNGlBCy6lIBFlxKw6FIC/w8j49UHob7oRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f78928f160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD3CAYAAAA0cknjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f789349cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# Predict single images\n",
    "n_images = 4\n",
    "# Get images from test set\n",
    "test_images = mnist.test.images[:n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': test_images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction:\", preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
